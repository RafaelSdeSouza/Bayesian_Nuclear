830/1596
install.packages("rJava",type = "source",http://rforge.net")
install.packages("rJava",type = "source","http://rforge.net")
install.packages("rJava",type = "source",,"http://rforge.net")
# From: Bayesian Models for Astrophysical Data, Cambridge Univ. Press
# (c) 2017,  Joseph M. Hilbe, Rafael S. de Souza and Emille E. O. Ishida
#
# you are kindly asked to include the complete citation if you used this
# material in a publication
# Code 4.10 - Normal linear model in R using JAGS and including errors in variables
require(R2jags)
# Data
set.seed(1056)                   # set seed to replicate example
nobs = 1000                      # number of obs in model
sdobsx <- 1.25
truex <- rnorm(nobs,0,2.5)       # normal variable
errx <- rnorm(nobs, 0, sdobsx)
obsx <- truex + errx
beta1 <- -4
beta2 <- 7
sdy <- 1.25
sdobsy <- 2.5
erry <- rnorm(nobs, 0, sdobsy)
truey <- rnorm(nobs,beta1 + beta2*truex,sdy)
obsy <- truey + erry
K <- 2
model.data <- list(obsy = obsy,
obsx = obsx,
K = K,
errx = errx,
erry = erry,
N = nobs)
NORM_err <-" model{
# Diffuse normal priors for predictors
for (i in 1:K) { beta[i] ~ dnorm(0, 1e-3) }
# Uniform prior for standard deviation
tauy <- pow(sigma, -2)                               # precision
sigma ~ dunif(0, 100)                                # diffuse prior for standard deviation
# Diffuse normal priors for true x
for (i in 1:N){
x[i] ~ dnorm(0,1e-3)
}
# Likelihood
for (i in 1:N){
obsy[i] ~ dnorm(y[i],pow(erry[i],-2))
y[i] ~ dnorm(mu[i],tauy)
obsx[i] ~ dnorm(x[i],pow(errx[i],-2))
mu[i] <- beta[1]+beta[2]*x[i]
}
}"
# Initial values
inits <- function () {
list(beta = rnorm(K, 0, 0.01))
}
# Parameter to display and save
params <- c("beta", "sigma")
evfit <- jags(data = model.data,
inits = inits,
parameters = params,
model = textConnection(NORM_err),
n.chains = 3,
n.iter = 5000,
n.thin = 1,
n.burnin = 2500)
print(evfit,intervals=c(0.025, 0.975), digits=3)
# Data
set.seed(1056)                   # set seed to replicate example
nobs = 1000                      # number of obs in model
sdobsx <- 1.25
truex <- rnorm(nobs,0,2.5)       # normal variable
#errx <- rnorm(nobs, 0, sdobsx)
#obsx <- truex + errx
beta1 <- -4
beta2 <- 7
sdy <- 1.25
sdobsy <- 2.5
erry <- rnorm(nobs, 0, sdobsy)
truey <- rnorm(nobs,beta1 + beta2*truex,sdy)
obsy <- truey + erry
K <- 2
model.data <- list(obsy = obsy,
obsx = obsx,
K = K,
errx = errx,
erry = erry,
N = nobs)
NORM_err <-" model{
# Diffuse normal priors for predictors
for (i in 1:K) { beta[i] ~ dnorm(0, 1e-3) }
# Uniform prior for standard deviation
tauy <- pow(sigma, -2)                               # precision
sigma ~ dunif(0, 100)                                # diffuse prior for standard deviation
# Likelihood
for (i in 1:N){
obsy[i] ~ dnorm(y[i],pow(erry[i],-2))
y[i] ~ dnorm(mu[i],tauy)
mu[i] <- beta[1]+beta[2]*truex[i]
}
}"
# Initial values
inits <- function () {
list(beta = rnorm(K, 0, 0.01))
}
# Parameter to display and save
params <- c("beta", "sigma")
evfit <- jags(data = model.data,
inits = inits,
parameters = params,
model = textConnection(NORM_err),
n.chains = 3,
n.iter = 5000,
n.thin = 1,
n.burnin = 2500)
print(evfit,intervals=c(0.025, 0.975), digits=3)
errx
# Data
set.seed(1056)                   # set seed to replicate example
nobs = 1000                      # number of obs in model
sdobsx <- 1.25
truex <- rnorm(nobs,0,2.5)       # normal variable
#errx <- rnorm(nobs, 0, sdobsx)
#obsx <- truex + errx
obsx <- truex
beta1 <- -4
beta2 <- 7
sdy <- 1.25
sdobsy <- 2.5
erry <- rnorm(nobs, 0, sdobsy)
truey <- rnorm(nobs,beta1 + beta2*truex,sdy)
obsy <- truey + erry
K <- 2
model.data <- list(obsy = obsy,
obsx = obsx,
K = K,
errx = errx,
erry = erry,
N = nobs)
NORM_err <-" model{
# Diffuse normal priors for predictors
for (i in 1:K) { beta[i] ~ dnorm(0, 1e-3) }
# Uniform prior for standard deviation
tauy <- pow(sigma, -2)                               # precision
sigma ~ dunif(0, 100)                                # diffuse prior for standard deviation
# Likelihood
for (i in 1:N){
obsy[i] ~ dnorm(y[i],pow(erry[i],-2))
y[i] ~ dnorm(mu[i],tauy)
mu[i] <- beta[1]+beta[2]*obsx[i]
}
}"
# Initial values
inits <- function () {
list(beta = rnorm(K, 0, 0.01))
}
# Parameter to display and save
params <- c("beta", "sigma")
evfit <- jags(data = model.data,
inits = inits,
parameters = params,
model = textConnection(NORM_err),
n.chains = 3,
n.iter = 5000,
n.thin = 1,
n.burnin = 2500)
print(evfit,intervals=c(0.025, 0.975), digits=3)
erry
print(evfit,intervals=c(0.025, 0.975), digits=3)
# Level of  mistake in the reported errors
Lambda <- 0.5
model.data <- list(obsy = obsy,
obsx = obsx,
K = K,
errx = errx,
erry = Lambda*erry,
N = nobs)
NORM_err <-" model{
# Diffuse normal priors for predictors
for (i in 1:K) { beta[i] ~ dnorm(0, 1e-3) }
# Uniform prior for standard deviation
tauy <- pow(sigma, -2)                               # precision
sigma ~ dunif(0, 100)                                # diffuse prior for standard deviation
# Likelihood
for (i in 1:N){
obsy[i] ~ dnorm(y[i],pow(erry[i],-2))
y[i] ~ dnorm(mu[i],tauy)
mu[i] <- beta[1]+beta[2]*obsx[i]
}
}"
# Initial values
inits <- function () {
list(beta = rnorm(K, 0, 0.01))
}
# Parameter to display and save
params <- c("beta", "sigma")
evfit <- jags(data = model.data,
inits = inits,
parameters = params,
model = textConnection(NORM_err),
n.chains = 3,
n.iter = 5000,
n.thin = 1,
n.burnin = 2500)
print(evfit,intervals=c(0.025, 0.975), digits=3)
setwd("~/")
erry
library(shiny)
library(DT)
shinyApp(
ui = fluidPage(
dataTableOutput('table'),
verbatimTextOutput('hoverIndex')
),
server = function(server, input, output) {
output$hoverIndex <- renderText({
paste("hover column info", input$hoverIndexJS)
})
output$table <- renderDataTable({
datatable(data.frame(`A` = 1:5, `B` = 11:15, `C` = LETTERS[1:5]),
rownames = F,
callback = JS("
table.on('mouseenter', 'td', function() {
Shiny.onInputChange('hoverIndexJS', this.innerHTML);
});
return table;
")
)
})
}
)
175/8
175*4
setwd("~/Documents/GitHub/JAGS_UNC/Scripts_R/Tdn/Real_data")
# 3Hedp analysis
#
# purpose: Real  DATA
#
# - 5 parameters are assumed: Er, gamma_d^2, gamma_n^2 [e1, gin, gout]
#
# - uses the function sfactorHe3dp(obsx1[i], e1, gin, gout), which
#   is a C++ version of a Fortran code that includes Coulomb wave
#   function calculations; JAGS has been recompiled with this C++ function
#
######################################################################
# preparation: remove all variables from the work space
rm(list=ls())
set.seed(123)
######################################################################
# data input
# format: obsx, obsy, errobsy; the latter are the individual statistical
# errors of each datum [i]
#
# energy is in units of MeV, and the S-factor in MeVb;
######################################################################
# import packages
library(rjags);library(R2jags);library(mcmcplots)
require(RcppGSL);require(ggplot2);require(ggthemes)
require(nuclear);library(magrittr);library(wesanderson)
library(dplyr);require(ggsci);require(ggmcmc);require(plyr);library(latex2exp)
source("..//..//auxiliar_functions/jagsresults.R")
source("..//..//auxiliar_functions/theme_rafa.R")
source("..//..//auxiliar_functions/pair_wise_plot.R")
source("..//..//auxiliar_functions/Gamma3Hedp.R")
## for block updating [we do not need to center predictor variables]
load.module("glm")
load.module("nuclear")
######################################################################
## Read DATA
ensamble <- read.csv("ensamble_Tdn_extra.csv",header = T) %>%  filter(E <= 0.3)
#filter(dat!= "Mag75")
#%>% filter(E <= 0.5) %>%   filter(dat!= "Arn53") %>%
# droplevels(ensamble$dat)
re <- as.numeric(ensamble$dat)
Nre <- length(unique(ensamble$dat))
Nik <- length(unique(ensamble$invK))
# Radius
# r_i = 6
# r_f = 5
# Literature
#  0.35779   # resonance energy
#  1.0085    # reduced width incoming
#  0.025425   # reduced width outgoing
N <- nrow(ensamble)
obsy <- ensamble$S    # Response variable
obsx <-  ensamble$E   # Predictors
erry <- ensamble$Stat
set <- ensamble$dat
lab <- ensamble$invK
syst = c(unique(ensamble$Syst))
#syst <- syst[-3]
library(BayesianTools)
likelihood <- function(par){
e1 = par[1]
gin = par[2]
gout = par[3]
sigmax = par[4]
scale = par[5:9]
y = par[10:(nobs + N)]
llRandom = sum(dlnorm(scale,meanlog = log(1), sdlog = log(1 + syst^2), log = T))
lly <- sum(dnorm(y,mean = scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5), sd = sigmax,  log = T))
llobs = sum(dnorm(obsy,mean = y,sd = erry,log = T))
#llobs = sum(dnorm(obsy,scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5),sd = sigmax,log = T))
#  obsy[i] ~ dnorm(y[i], pow(erry[i], -2))
#  y[i] ~ dnorm(scale[re[i]]*sfactorTdn(obsx[i], e1, ex,gin, gout,ri,rf,0),pow(tau, -2))
#  llytrue = sum(dnorm(scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5),
#                      sd = sigmax, log = T))
#  llobs = sum(dnorm(obsy,mean = llytrue,sd = erry,log = T))
#llobs = sum(dnorm(scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5) - obsy,sd = sigmax,log = T))
return(llRandom + llobs + lly)
}
setup <- createBayesianSetup(likelihood = likelihood,
lower = c(0.001,0.001,0.001,0.001,rep(0.5,5),obsy - 3*abs(erry)),
upper = c(1,2,2,5,rep(1.5,5),obsy + 3*abs(erry)))
settings <- list(iterations = 10000,
burnin = 1500, message=T)
res <- runMCMC(bayesianSetup = setup, settings = settings)
likelihood <- function(par){
e1 = par[1]
gin = par[2]
gout = par[3]
sigmax = par[4]
scale = par[5:9]
y = par[10:(N+9)]
llRandom = sum(dlnorm(scale,meanlog = log(1), sdlog = log(1 + syst^2), log = T))
lly <- sum(dnorm(y,mean = scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5), sd = sigmax,  log = T))
llobs = sum(dnorm(obsy,mean = y,sd = erry,log = T))
#llobs = sum(dnorm(obsy,scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5),sd = sigmax,log = T))
#  obsy[i] ~ dnorm(y[i], pow(erry[i], -2))
#  y[i] ~ dnorm(scale[re[i]]*sfactorTdn(obsx[i], e1, ex,gin, gout,ri,rf,0),pow(tau, -2))
#  llytrue = sum(dnorm(scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5),
#                      sd = sigmax, log = T))
#  llobs = sum(dnorm(obsy,mean = llytrue,sd = erry,log = T))
#llobs = sum(dnorm(scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5) - obsy,sd = sigmax,log = T))
return(llRandom + llobs + lly)
}
setup <- createBayesianSetup(likelihood = likelihood,
lower = c(0.001,0.001,0.001,0.001,rep(0.5,5),obsy - 3*abs(erry)),
upper = c(1,2,2,5,rep(1.5,5),obsy + 3*abs(erry)))
settings <- list(iterations = 10000,
burnin = 1500, message=T)
res <- runMCMC(bayesianSetup = setup, settings = settings)
summary(res)
tracePlot(sampler = res, thin = 10, start = 20000, whichParameters = c(1,2,3))
tracePlot(sampler = res, thin = 10, start = 2000, whichParameters = c(1,2,3))
obsy - 3*abs(erry)
erry
setup <- createBayesianSetup(likelihood = likelihood,
lower = c(0.001,0.001,0.001,0.001,rep(0.5,5),obsy - 5*abs(erry)),
upper = c(1,2,2,5,rep(1.5,5),obsy + 5*abs(erry)))
settings <- list(iterations = 50000,
burnin = 15000, message=T)
res <- runMCMC(bayesianSetup = setup, settings = settings)
summary(res)
tracePlot(sampler = res, thin = 10, start = 2000, whichParameters = c(1,2,3))
summary(res,whichParameters = c(1,2,3))
codaObject = getSample(res, start = 500, coda = TRUE)
codaObject
as.mcmc.rjags(codaObject)
as.mcmc(codaObject)
getmcmc_var <- function(outjags=outjags,vars = vars){
as.data.frame(do.call(rbind, as.mcmc(outjags)[,vars]))
}
getmcmc_var(codaObject,vars=c("par[1]")
getmcmc_var(codaObject,vars=c("par[1]"))
getmcmc_var(codaObject,vars=c("par[1]"))
as.mcmc(codaObject)
getmcmc_var <- function(outjags=outjags,vars = vars){
as.data.frame(do.call(rbind, outjags[,vars]))
}
getmcmc_var(codaObject,vars=c("par[1]"))
codaObject[1,]
codaObject[,1]
codaObject[,"par[1]"]
codaObject[,"par [1]"]
codaObject[1,1]
codaObject[,"par 1"]
getmcmc_var(codaObject,vars=c("par 1"))
getmcmc_var <- function(outjags=outjags,vars = vars){
as.data.frame(do.call(rbind, outjags[,vars]))
}
getmcmc_var(codaObject,vars=c("par 1"))
getmcmc_var(codaObject,vars = c("par 1","par 2"))
getmcmc_var(codaObject,vars = c("par 1","par 2","par 3","par 4"))
to("m", 10)
install.packages("lessR")
require(lessR)
to("m", 10)
re
ensamble <- read.csv("ensamble_Tdn_extra.csv",header = T) %>%  filter(E <= 0.5)
#filter(dat!= "Mag75")
#%>% filter(E <= 0.5) %>%   filter(dat!= "Arn53") %>%
# droplevels(ensamble$dat)
re <- as.numeric(ensamble$dat)
Nre <- length(unique(ensamble$dat))
Nik <- length(unique(ensamble$invK))
# Radius
# r_i = 6
# r_f = 5
# Literature
#  0.35779   # resonance energy
#  1.0085    # reduced width incoming
#  0.025425   # reduced width outgoing
N <- nrow(ensamble)
obsy <- ensamble$S    # Response variable
obsx <-  ensamble$E   # Predictors
erry <- ensamble$Stat
set <- ensamble$dat
lab <- ensamble$invK
syst = c(unique(ensamble$Syst))
#syst <- syst[-3]
library(BayesianTools)
re
c("e0","gd","gp","sigma",to("scale", 5))
N
c("e0","gd","gp","sigma",to("scale", 5),to("y", N))
setup <- createBayesianSetup(likelihood = likelihood,
lower = c(0.001,0.001,0.001,0.001,rep(0.5,5),obsy - 5*abs(erry)),
upper = c(1,2,2,5,rep(1.5,5),obsy + 5*abs(erry)),
names = c("e0","gd","gp","sigma",to("scale", 5),to("y", N)))
settings <- list(iterations = 100000,
burnin = 25000, message=T)
res <- runMCMC(bayesianSetup = setup, settings = settings)
summary(res)
tracePlot(sampler = res, thin = 10, start = 2000, whichParameters = c(1,2,3))
syst
erry
likelihood <- function(par){
e1 = par[1]
gin = par[2]
gout = par[3]
sigmax = par[4]
scale = par[5:9]
y = par[10:(N + 9)]
llRandom = sum(dlnorm(scale,meanlog = log(1), sdlog = log(1 + syst^2), log = T))
lly <- sum(dnorm(y,mean = scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5), sd = sigmax,  log = T))
llobs = sum(dnorm(obsy,mean = y,sd = erry,log = T))
return(llRandom + llobs + lly)
}
setup <- createBayesianSetup(likelihood = likelihood,
lower = c(0.001,0.001,0.001,0.001,rep(0.5,5),obsy - 5*abs(erry)),
upper = c(1,2,2,5,rep(1.5,5),obsy + 5*abs(erry)),
names = c("e0","gd2","gn2","sigma",to("scale", 5),to("y", N)))
names = c("e0","gd2","gn2","sigma",to("scale", 5),to("y", N)))
settings <- list(iterations = 200000,
burnin = 50000, message = T)
res <- runMCMC(bayesianSetup = setup, settings = settings)
c("e0","gd2","gn2","sigma",to("scale", 5),to("y", N))
# 3Hedp analysis
#
# purpose: Real  DATA
#
# - 5 parameters are assumed: Er, gamma_d^2, gamma_n^2 [e1, gin, gout]
#
# - uses the function sfactorHe3dp(obsx1[i], e1, gin, gout), which
#   is a C++ version of a Fortran code that includes Coulomb wave
#   function calculations; JAGS has been recompiled with this C++ function
#
######################################################################
# preparation: remove all variables from the work space
rm(list=ls())
set.seed(123)
######################################################################
# data input
# format: obsx, obsy, errobsy; the latter are the individual statistical
# errors of each datum [i]
#
# energy is in units of MeV, and the S-factor in MeVb;
######################################################################
# import packages
require(RcppGSL);require(ggplot2);require(ggthemes)
require(nuclear);library(magrittr);
library(dplyr);require(lessR);library(BayesianTools)
######################################################################
## Read DATA
ensamble <- read.csv("ensamble_Tdn_extra.csv",header = T) %>%  filter(E <= 0.5)
#filter(dat!= "Mag75")
#%>% filter(E <= 0.5) %>%   filter(dat!= "Arn53") %>%
# droplevels(ensamble$dat)
re <- as.numeric(ensamble$dat)
Nre <- length(unique(ensamble$dat))
Nik <- length(unique(ensamble$invK))
N <- nrow(ensamble)
obsy <- ensamble$S    # Response variable
obsx <-  ensamble$E   # Predictors
erry <- ensamble$Stat
set <- ensamble$dat
lab <- ensamble$invK
syst = c(unique(ensamble$Syst))
likelihood <- function(par){
e1 = par[1]
gin = par[2]
gout = par[3]
sigmax = par[4]
scale = par[5:9]
y = par[10:(N + 9)]
llRandom = sum(dlnorm(scale,meanlog = log(1), sdlog = log(1 + syst^2), log = T))
lly <- sum(dnorm(y,mean = scale[re]*sfactorTdn_5p(obsx, e1,gin, gout,6,5), sd = sigmax,  log = T))
llobs = sum(dnorm(obsy,mean = y,sd = erry,log = T))
return(llRandom + llobs + lly)
}
setup <- createBayesianSetup(likelihood = likelihood,
lower = c(0.001,0.001,0.001,0.001,rep(0.5,5),obsy - 5*abs(erry)),
upper = c(1,2,2,5,rep(1.5,5),obsy + 5*abs(erry)),
names = c("e0","gd2","gn2","sigma",to("scale", 5),to("y", N)))
settings <- list(iterations = 200000,
burnin = 50000, message = T)
res <- runMCMC(bayesianSetup = setup, settings = settings)
summary(res)
tracePlot(sampler = res, thin = 10, start = 2000, whichParameters = c(1,2,3))
tracePlot(sampler = res, thin = 10, start = 10000, whichParameters = c(1,2,3))
tracePlot(sampler = res, thin = 10, start = 20000, whichParameters = c(1,2,3))
tracePlot(sampler = res, thin = 10, start = 5000, whichParameters = c(1,2,3))
tracePlot(sampler = res, thin = 10, start = 5000, whichParameters = c(1,2,3,4,5,6,7,8,9))
