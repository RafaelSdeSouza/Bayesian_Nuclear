expand.grid(x1,x2)
LK2(expand.grid(x1,x2))
xy <- expand.grid(x1,x2)
xy[,1]
LK2(xy[,1],xy[,2])
LK2(xy[,1],xy[,2])
xy[,1]
sapply(LK2,xy)
sapply(xy,LK2)
sapply(LK2,xy)
LK2 <- function(x1,x2) {return(
likelihood(c(0.0912,x1,x2)))
}
sapply(xy,LK2)
xy <- expand.grid(x1=x1,x1=x2)
sapply(xy,LK2)
xy
sapply(xy$x1,xy$x1,LK2)
sapply(xy$x1,xy$x2,LK2)
require(GA)
SF<- function(x1, x2){
sfactorTdn(ER=0.0912,gi=x1,gf=x2)
}
x <- runif(100, 0.01, 0.3)
erry<- runif( 100, 0.01, 0.1)
y <- rnorm( 100, sfactorTdn(x,  0.0912, 2.93 , 0.0794), erry^2)
likelihood <- function(param){
"Likelihood function"
er = param[1]
gi = param[2]
gf = param[3]
LL = sum(((y - sfactorTdn(x,er,gi,gf))^2)/erry^2)
return(-log(LL))
}
LK2 <- function(x1,x2) {return(
likelihood(c(0.0912,x1,x2)))
}
xy <- expand.grid(x1=x1,x1=x2)
sapply(xy$x1,xy$x2,LK2)
x1 <- x2 <- seq(0.001, 20, by = 0.1)
slopevalues <- function(y){return(likelihood(c(0.0912,x1,x2)))}
slopevalues
x1
x2
slopevalues <- function(x1,x2){return(likelihood(c(0.0912,x1,x2)))}
slopevalues
xy
xy <- expand.grid(x1=x1,x1=x2)
sapply(xy ,slopevalues)
sapply(c(x1,x2),slopevalues)
apply(c(x1,x2),slopevalues)
apply(xy,slopevalues)
apply(xy,1,slopevalues)
xy <- expand.grid(x1=x1,x2=x2)
apply(xy,2,slopevalues)
apply(xy,1,slopevalues)
x
xy <- expand.grid(x1=x1,x2=x2)
xy
apply(xy,1,slopevalues)
xy1
xy
xy[1,]
apply(xy,2,slopevalues)
slopevalues(xy)
slopevalues(xy[1,])
slopevalues(xy[,1],xy[,1])
slopevalues(xy[1,1],xy[1,1])
slopevalues(1,1)
slopevalues <- function(x1,x2){return(likelihood(c(0.0912,x1,x2)))}
slopevalues(1,1)
y
require(nuclear)
y <- rnorm( 100, sfactorTdn(x,  0.0912, 2.93 , 0.0794), erry^2)
likelihood <- function(param){
"Likelihood function"
er = param[1]
gi = param[2]
gf = param[3]
LL = sum(((y - sfactorTdn(x,er,gi,gf))^2)/erry^2)
return(-log(LL))
}
LK2 <- function(x1,x2) {return(
likelihood(c(0.0912,x1,x2)))
}
slopevalues <- function(x1,x2){return(likelihood(c(0.0912,x1,x2)))}
slopevalues(1,1)
slopevalues(xy[,1],xy[,2])
slopevalues(xy)
apply(xy,2,slopevalues)
xy
as.data.frame(xy)
xy <- as.data.frame(xy)
slopevalues <- function(x1,x2){return(likelihood(c(0.0912,x1,x2)))}
apply(xy,2,slopevalues)
Vectorize(slopevalues)
slopevalues <- Vectorize(slopevalues)
slopevalues(xy)
slopevalues
slopevalues(xy$x1,xy$x2)
f <- slopevalues(xy$x1,xy$x2)
persp3D(x1, x2, f, theta = 50, phi = 20)
persp3D(xy, f, theta = 50, phi = 20)
f
200*200
xy
persp3D(xy$x1,xy$x2, f, theta = 50, phi = 20)
xy$x1
xy$x2
z <- outer(x1, x2, slopevalues)
persp3D(x, y, z, theta = 50, phi = 20)
persp3D(x1, x2, z, theta = 50, phi = 20)
persp3D(x1, x2, z, theta = 50, phi = 30)
persp3D(x1, x2, z, theta = 80, phi = 30)
persp3D(x1, x2, z, theta = 80, phi = 20)
x1 <- x2 <- seq(0.001, 5, by = 0.1)
slopevalues <- function(x1,x2){return(likelihood(c(0.0912,x1,x2)))}
slopevalues <- Vectorize(slopevalues)
z <- outer(x1, x2, slopevalues)
persp3D(x1, x2, z, theta = 80, phi = 20)
persp3D(x1, x2, z, theta = 60, phi = 20)
persp3D(x1, x2, z, theta = 60, phi = 60)
persp3D(x1, x2, z, theta = 60, phi = 25)
persp3D(x1, x2, z, theta = 160, phi = 25)
persp3D(x1, x2, z, theta = 140, phi = 25)
persp3D(x1, x2, z, theta = 120, phi = 25)
persp3D(x1, x2, z, theta = 110, phi = 25)
persp3D(x1, x2, z, theta = 90, phi = 25)
persp3D(x1, x2, z, theta = 100, phi = 25)
persp3D(x1, x2, z, theta = 100, phi = 35)
persp3D(x1, x2, z, theta = 100, phi = 15)
x1 <- x2 <- seq(0.001, 2, by = 0.01)
slopevalues <- function(x1,x2){return(likelihood(c(0.0912,x1,x2)))}
slopevalues <- Vectorize(slopevalues)
z <- outer(x1, x2, slopevalues)
persp3D(x1, x2, z, theta = 100, phi = 15)
x1 <-  seq(0.001, 3.5, by = 0.01)
x2 <-  seq(0.001, 1, by = 0.01)
slopevalues <- function(x1,x2){return(likelihood(c(0.0912,x1,x2)))}
slopevalues <- Vectorize(slopevalues)
z <- outer(x1, x2, slopevalues)
persp3D(x1, x2, z, theta = 100, phi = 15)
x1 <-  seq(0.001, 3.5, by = 0.01)
x2 <-  seq(0.001, 0.2, by = 0.01)
slopevalues <- function(x1,x2){return(likelihood(c(0.0912,x1,x2)))}
slopevalues <- Vectorize(slopevalues)
z <- outer(x1, x2, slopevalues)
persp3D(x1, x2, z, theta = 100, phi = 15)
persp3D(x1, x2, z, theta = 60, phi = 15)
GA <- ga(type = "real-valued", fitness =  function(x) -slopevalues(x[1],x[2]),
min = c(0.001, 0.001, max = c(5, 5),
popSize = 50, maxiter = 100)
summary(GA)
GA <- ga(type = "real-valued", fitness =  function(x) -slopevalues(x[1],x[2]),
min = c(0.001, 0.001, max = c(5, 5),
popSize = 50, maxiter = 100)
ga(type = "real-valued", fitness =  function(x) -slopevalues(x[1],x[2]),
min = c(0.001, 0.001, max = c(5, 5),
popSize = 50, maxiter = 100)
ga(type = "real-valued", fitness =  function(x) -slopevalues(x[1],x[2]),
min = c(0.001, 0.001, max = c(5, 5),
popSize = 50, maxiter = 100)
GA <- ga(type = "real-valued", fitness =  function(x) -slopevalues(x[1],x[2]),
min = c(0.001, 0.001), max = c(5, 5),
popSize = 50, maxiter = 100)
GA <- ga(type = "real-valued", fitness =  function(x) -slopevalues(x[1],x[2]),
min = c(0.001, 0.001), max = c(5, 5),
popSize = 50, maxiter = 100)
summary(GA)
plot(GA)
GA <- ga(type = "real-valued", fitness =  function(x) -slopevalues(x[1],x[2]),
min = c(0.001, 0.001), max = c(5, 5),
popSize = 50, maxiter = 500)
summary(GA)
summary(GA)
plot(GA)
GA <- ga(type = "real-valued", fitness =  function(x) -slopevalues(x[1],x[2]),
min = c(0.0001, 0.0001), max = c(10, 10),
popSize = 100, maxiter = 1000)
summary(GA)
plot(GA)
summary(GA)
plot(GA)
filled.contour(x1, x2, z, color.palette = jet.colors)
filled.contour(x1, x2, z, color.palette = terrain.colors)
filled.contour(x1, x2, z, color.palette = terrain.colors,nlevels = 200)
filled.contour(x1, x2, z, color.palette = terrain.colors,nlevels = 100)
filled.contour(x1, x2, z, color.palette = terrain.colors,nlevels = 100,key.axes=F)
levelplot(z~x1*x2, grid, cuts = 100)
require(lattice)
levelplot(z~x1*x2, grid, cuts = 100)
levelplot(z~x1*x2,  cuts = 100)
levelplot(z~x1*x2,  cuts = 100,color.palette = terrain.colors)
levelplot(z~x1*x2,  cuts = 100,color.palette = terrain.colors,region = TRUE)
filled.contour(x1, x2, z, color.palette = terrain.colors,nlevels = 100)
filled.contour(x1, x2, z,nlevels = 100)
library(RColorBrewer)
darkcols <- brewer.pal(8, "Dark2")
filled.contour(x1, x2, z,color.palette=darkcols, nlevels = 100)
filled.contour(x1, x2, z, color.palette = darkcols ,nlevels = 100)
filled.contour(x1, x2, z, color.palette = terrain.colors,nlevels = 100)
terrain.colors
filled.contour(x1, x2, z, color.palette=colorRampPalette(c('white','blue','yellow','red','darkred')),nlevels = 100)
15*30
15*40
14+24
38*10
2*3/2+1
1+1
2*3
exp(0.1)
log(1.10\)
log(1.10)
0.1*1e6
1e5/1e3
500000/43
cite("fields")
cite("fields",bib = T)
cite("fields",bib)
citation("fields",bib)
citation("fields")
0.24742-0.24709
0.24709-0.24676
0.00033/2
2.532-2.460
2.460-2.386
1.127-1.074
1.074-1.023
6.105-5.627
5.627-5.123
setwd("~/Documents/GitHub/Autoencoders/Cepheids")
library(h2)
require(mclust)
h2o.init()
Lyrae <- read.table("blg_met_rrl.dat",header=T) %>% mutate(.,Period = log10(Period)) %>%
filter(X.Fe.H. > -1.647874 && X.Fe.H. < -0.279256)
#test_index <- sample(seq_len(nrow(Lyrae)),replace=F, size = 20000)
#Lyrae_short <- Lyrae[test_index,c("Period","X.Fe.H.","R21","Imag")]
LyraeH20  <- as.h2o(Lyrae)
parts <- h2o.splitFrame(LyraeH20,0.8)
train <- parts[[1]]
test <- parts[[2]]
m_AE_4 = h2o.deeplearning(x = c("Period","X.Fe.H.","R21","R31","Imag","Vmag"),
training_frame=train,
autoencoder=TRUE,
epochs = 500,
score_each_iteration=T,
model_id = "m_AE_4",
train_samples_per_iteration=nrow(train),
activation = "Tanh",
hidden = c(4,3,2,3,4)
)
sh = h2o.scoreHistory(m_AE_4)
plot(as.data.frame(h2o.scoreHistory(m_AE_4))$training_mse,type="l")
train_1 <- h2o.deepfeatures(m_AE_4,train,layer=3)
d1 <- as.data.frame(train_1)
plot(density(d1$DF.L3.C1))
dens  <- Mclust(train_1,G = 3)
setwd("~/Documents/GitHub/Autoencoders/Cepheids")
library(h2)
require(mclust)
h2o.init()
Lyrae <- read.table("blg_met_rrl.dat",header=T) %>% mutate(.,Period = log10(Period)) %>%
filter(X.Fe.H. > -1.647874 && X.Fe.H. < -0.279256)
#test_index <- sample(seq_len(nrow(Lyrae)),replace=F, size = 20000)
#Lyrae_short <- Lyrae[test_index,c("Period","X.Fe.H.","R21","Imag")]
LyraeH20  <- as.h2o(Lyrae)
parts <- h2o.splitFrame(LyraeH20,0.8)
train <- parts[[1]]
test <- parts[[2]]
m_AE_4 = h2o.deeplearning(x = c("Period","X.Fe.H.","R21","R31","Imag","Vmag"),
training_frame=train,
autoencoder=TRUE,
epochs = 500,
score_each_iteration=T,
model_id = "m_AE_4",
train_samples_per_iteration=nrow(train),
activation = "Tanh",
hidden = c(4,3,2,3,4)
)
sh = h2o.scoreHistory(m_AE_4)
plot(as.data.frame(h2o.scoreHistory(m_AE_4))$training_mse,type="l")
train_1 <- h2o.deepfeatures(m_AE_4,train,layer=3)
d1 <- as.data.frame(train_1)
plot(density(d1$DF.L3.C1))
dens  <- Mclust(train_1,G = 3)
h2o.init()
library(h20)
library(h2o)
library(h2o)
require(mclust)
h2o.init()
Lyrae <- read.table("blg_met_rrl.dat",header=T) %>% mutate(.,Period = log10(Period)) %>%
filter(X.Fe.H. > -1.647874 && X.Fe.H. < -0.279256)
require(dplyr)
library(h2o)
require(mclust)
require(dplyr)
h2o.init()
Lyrae <- read.table("blg_met_rrl.dat",header=T) %>% mutate(.,Period = log10(Period)) %>%
filter(X.Fe.H. > -1.647874 && X.Fe.H. < -0.279256)
LyraeH20  <- as.h2o(Lyrae)
parts <- h2o.splitFrame(LyraeH20,0.8)
train <- parts[[1]]
test <- parts[[2]]
m_AE_4 = h2o.deeplearning(x = c("Period","X.Fe.H.","R21","R31","Imag","Vmag"),
training_frame=train,
autoencoder=TRUE,
epochs = 500,
score_each_iteration=T,
model_id = "m_AE_4",
train_samples_per_iteration=nrow(train),
activation = "Tanh",
hidden = c(4,3,2,3,4)
)
sh = h2o.scoreHistory(m_AE_4)
plot(as.data.frame(h2o.scoreHistory(m_AE_4))$training_mse,type="l")
train_1 <- h2o.deepfeatures(m_AE_4,train,layer=3)
d1 <- as.data.frame(train_1)
plot(density(d1$DF.L3.C1))
dens  <- Mclust(train_1,G = 3)
plot(as.data.frame(train[,c("Period","X.Fe.H.","R21","R31","Imag","Vmag")]),col=dens$classification)
head(Lyrae )
Lyrae <- read.table("blg_met_rrl.dat",header=T) %>% mutate(.,LogP = log10(Period)) %>%
filter(X.Fe.H. > -1.647874 && X.Fe.H. < -0.279256) %>% mutate(.,"V.I" = Vmag - Imag ) %>%
mutate(.,"Iamp_R31 " = Iamp/R31)
head(Lyrae )
Lyrae <- read.table("blg_met_rrl.dat",header=T) %>% mutate(.,LogP = log10(Period)) %>%
filter(X.Fe.H. > -1.647874 && X.Fe.H. < -0.279256) %>% mutate(.,"V.I" = Vmag - Imag) %>%
mutate(.,"Iamp_R31" = Iamp/R31)
#Vmag-Imag (that's proxy for temperature), Imag (proxy for luminosity), or Iamp/R31
#test_index <- sample(seq_len(nrow(Lyrae)),replace=F, size = 20000)
#Lyrae_short <- Lyrae[test_index,c("Period","X.Fe.H.","R21","Imag")]
LyraeH20  <- as.h2o(Lyrae)
parts <- h2o.splitFrame(LyraeH20,0.8)
train <- parts[[1]]
test <- parts[[2]]
m_AE_4 = h2o.deeplearning(x = c("LogP","X.Fe.H.","R21","V.I","Imag","Iamp_R31"),
training_frame=train,
autoencoder=TRUE,
epochs = 500,
score_each_iteration=T,
model_id = "m_AE_4",
train_samples_per_iteration=nrow(train),
activation = "Tanh",
hidden = c(4,3,2,3,4)
)
sh = h2o.scoreHistory(m_AE_4)
plot(as.data.frame(h2o.scoreHistory(m_AE_4))$training_mse,type="l")
train_1 <- h2o.deepfeatures(m_AE_4,train,layer=3)
d1 <- as.data.frame(train_1)
plot(density(d1$DF.L3.C1))
dens  <- Mclust(train_1)
summary(dens)
plot(as.data.frame(train[,c("LogP","X.Fe.H.","R21","V.I","Imag","Iamp_R31")]),col=dens$classification)
Lyrae
Lyrae <- Lyrae[,c("LogP","X.Fe.H.","R21","V.I","Imag","Iamp_R31")]
Lyrae
quantile(Lyrae[,1])
require(MVN)
install.packages("MVN")
require(MVN)
mvOutlier(Lyrae, qqplot = TRUE, method = "adj.quan")
require(MVN)
mvOutlier(Lyrae, qqplot = TRUE, method = "adj.quan")
install.packages("outliers")
library(outliers)
100*1e-6
1e-4*1e6
setwd("~/Documents/GitHub/JAGS_UNC/Scripts_R/He3dp/Real_data")
# preparation: remove all variables from the work space
rm(list=ls())
set.seed(27)
######################################################################
# data input
# format: obsx, obsy, errobsy; the latter are the individual statistical
# errors of each datum [i]
#
# energy is in units of MeV, and the S-factor in MeVb;
######################################################################
# import packages
require(RcppGSL);require(ggplot2);require(ggthemes)
require(nuclear);library(magrittr);
library(dplyr);require(lessR);library(BayesianTools)
require(msm)
source("..//..//auxiliar_functions/pair_wise_plot.R")
######################################################################
## Read DATA
ensamble <- read.csv("ensamble.csv",header = T) %>%
mutate(Syst=replace(Syst,Syst==0.06,0.078))  %>% filter(E <= 0.5)
re <- as.numeric(ensamble$dat)
Nre <- length(unique(ensamble$dat))
ik <- as.numeric(ensamble$invK)
Nik <- length(unique(ensamble$invK))
# Radius
# r_i = 6
# r_f = 5
# Literature
#  0.35779   # resonance energy
#  1.0085    # reduced width incoming
#  0.025425   # reduced width outgoing
N <- nrow(ensamble)
obsy <- ensamble$S    # Response variable
obsx <-  ensamble$E   # Predictors
erry <- ensamble$Stat
set <- ensamble$dat
lab <- ensamble$invK
syst = 1 + c(0.03,unique(ensamble$Syst))
likelihood <- function(par){
e0 = par[1]
er = par[2]
gd2 = par[3]
gp2 = par[4]
ad   = par[5]
ap =  par[6]
sigmax = par[7]
scale = par[8:14]
ue = par[15:16]
y = par[17:(N + 16)]
llRandom = sum(dlnorm(scale,meanlog = log(1), sdlog = log(syst), log = T))
lly <- sum(dnorm(y,mean = scale[re]*sfactor3Hedp_5p(obsx, e0,er,gd2, gp2,ad,ap,ue = ue[ik]), sd = sigmax,  log = T))
llobs = sum(dnorm(obsy,mean = y,sd = erry,log = T))
return(llRandom + llobs + lly)
}
low <- c(0.1,1e-3,rep(1e-4,2), 1,1,1e-4,rep(0.5,7),rep(0,2),obsy - 2*erry)
up <- c(0.4,1,rep(3,2),10,10,5,rep(1.5,7),rep(350,2),obsy + 2*erry)
createHedPrior <- function(lower, upper, best = NULL){
density = function(par){
d1 = dunif(par[1], 0.1, 0.4,log = TRUE)
d2 = dtnorm(par[1], 0, 1,log = TRUE)
d3 = dtnorm(par[3], 0, 34.625/par[5]^2, log = TRUE)
d4 = dtnorm(par[4], 0, 51.94605/par[6]^2, log = TRUE)
d5 = sum(dunif(par[5:6], 2, 10, log = TRUE))
d6 = dtnorm(par[7], mean = 0, sd = 5, log = TRUE)
d7 = sum(dlnorm(par[8:14],log(1),log(syst),log = TRUE))
d8 = sum(dtnorm(par[15:16], mean = 0, sd = 100, log = TRUE))
d9 = sum(dunif(par[17:(N + 16)],obsy - 2*erry,obsy + 2*erry,log = TRUE))
return(d1 + d2 + d3 + d4 + d5 + d6 + d7 + d8 + d9)
}
sampler = function(){
c(runif(1, 0.1, 0.35),
runif(1, 0, 1),
exp(runif(2, log(1e-3), log(2))),
runif(2, 2.5, 7),
runif(1, 0, 5),
rlnorm(7, log(1), log(syst)), #ynorm
runif(2, 0, 300),
runif(N, obsy - 2*erry,obsy + 2*erry)
)
}
out <- createPrior(density = density, sampler = sampler, lower = lower, upper = upper, best = best)
return(out)
}
prior <- createHedPrior(lower = low, upper = up)
likelihood <- function(par){
e0 = par[1]
er = par[2]
gd2 = par[3]
gp2 = par[4]
ad   = par[5]
ap =  par[6]
sigmax = par[7]
scale = par[8:14]
ue = par[15:16]
y = par[17:(N + 16)]
llRandom = sum(dlnorm(scale,meanlog = log(1), sdlog = log(syst), log = T))
lly <- sum(dnorm(y,mean = scale[re]*sfactor3Hedp_5p(obsx, e0,er,gd2, gp2,ad,ap,ue = ue[ik]), sd = sigmax,  log = T))
llobs = sum(dnorm(obsy,mean = y,sd = erry,log = T))
return(llRandom + llobs + lly)
}
low <- c(0.1,1e-3,rep(1e-4,2), 1,1,1e-4,rep(0.5,7),rep(0,2),obsy - 2*erry)
up <- c(0.4,1,rep(3,2),10,10,5,rep(1.5,7),rep(350,2),obsy + 2*erry)
createHedPrior <- function(lower, upper, best = NULL){
density = function(par){
d1 = dunif(par[1], 0.1, 0.4,log = TRUE)
d2 = dtnorm(par[1], 0, 1,log = TRUE)
d3 = dtnorm(par[3], 0, 34.625/par[5]^2, log = TRUE)
d4 = dtnorm(par[4], 0, 51.94605/par[6]^2, log = TRUE)
d5 = sum(dunif(par[5:6], 2, 10, log = TRUE))
d6 = dtnorm(par[7], mean = 0, sd = 5, log = TRUE)
d7 = sum(dlnorm(par[8:14],log(1),log(syst),log = TRUE))
d8 = sum(dtnorm(par[15:16], mean = 0, sd = 100E3, log = TRUE))
d9 = sum(dunif(par[17:(N + 16)],obsy - 2*erry,obsy + 2*erry,log = TRUE))
return(d1 + d2 + d3 + d4 + d5 + d6 + d7 + d8 + d9)
}
sampler = function(){
c(runif(1, 0.1, 0.35),
runif(1, 0, 1),
exp(runif(2, log(1e-3), log(2))),
runif(2, 2.5, 7),
runif(1, 0, 5),
rlnorm(7, log(1), log(syst)), #ynorm
runif(2, 0, 300),
runif(N, obsy - 2*erry,obsy + 2*erry)
)
}
out <- createPrior(density = density, sampler = sampler, lower = lower, upper = upper, best = best)
return(out)
}
prior <- createHedPrior(lower = low, upper = up)
#prior <- createUniformPrior(lower = low,
#                            upper = up)
setup <- createBayesianSetup(likelihood = likelihood,prior = prior,
names = c("e0","er","gd2","gp2","ad","ap","sigma",to("scale", 7),to("ue", 2),to("y", N)))
#setup <- createBayesianSetup(likelihood = likelihood,lower = low,upper = up,
#names = c("e0","er","gd2","gp2","ad","ap","sigma",to("scale", 7),to("ue", 2),to("y", N)))
settings <- list(iterations = 1E6,thin=5,
burnin = 2.5E5, message = T,nrChains = 1)
system.time(
res <- runMCMC(bayesianSetup = setup, settings = settings,sampler = "DEzs")
)
summary(res)
