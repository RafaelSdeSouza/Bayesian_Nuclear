geom_density_2d()
tolerance=c(1,0.75,0.5,0.25,0.15)
# Run Sequencial Approximate Bayesian Computation
ABC_Beaumont <- ABC_sequential(method="Beaumont", model=toy_model,
prior=toy_prior, nb_simul=1e4, summary_stat_target=sum_stat_obs,
tolerance_tab=tolerance)
# Plot histogram
hist(ABC_Beaumont$param[,1])
# Plot density 2D
pdat <- as.data.frame(ABC_Beaumont$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_density_2d()
hist(ABC_Beaumont$param[,2])
hist(ABC_Beaumont$param[,3])
hist(ABC_Beaumont$param[,4])
hist(ABC_Beaumont$param[,1])
pdat <- as.data.frame(ABC_Beaumont$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_density_2d()
toy_model(c(x1,x2,x3,x4))
9200+1200
10400 + 3100
13500*3.9
52650 + 47000
9200+1300+3100
require(EasyABC)
require(ggplot2)
# Toy programm
# ======================================================================
#   COMPUTE PREDICTED VALUES: BLACK BOX
# ======================================================================
#     the numbers in the following equations are "hidden"
toy_model <- function(par){
val1 <- 1e-1*par[1]^4 +
2e-1*par[2]^3.0 +
7e-1*par[3]^2 +
4e-1*par[4];
val2 <- 3e-2*par[1]^4.0 +
5e-2*par[2]^3.0 +
9e-2*par[3]^2.0 +
1e-2*par[4];
val3 <- 7e-3*par[1]^4.0 +
1e-3*par[2]^3.0 +
4e-3*par[3]^2 +
2e-3*par[4];
val4 <- 2e-4*par[1]^4 +
5e-4*par[2]^3 +
8e-4*par[3]^2 +
8e-4*par[4]
val5 <- 9e-5*par[1]^4 +
6e-5*par[2]^3 +
3e-5*par[3]^2 +
1e-5*par[4]
#S1 <- mean(c(val1,val2,val3,val4))
#S2 <- sd(c(val1,val2,val3,val4))
return(c(log(val1),log(val2),log(val3),log(val4),log(val5)))
}
# Observed data
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
# Summary, just the data - no compression
sum_stat_obs <- obs_data
toy_prior <- list(c("unif",1e-1,1e3),c("unif",1e-1,1e3),
c("unif",1e-1,1e3),c("unif",1e-1,1e3))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=10
n_calib=10
tol_quant=0.2
ABC_Wegmann<-ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n, n_calibration=n_calib,
tolerance_quantile=tol_quant, use_seed=TRUE)
ABC_Wegmann
n=1e3
n_calib=1e2
tol_quant=0.1
ABC_Wegmann<-ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n, n_calibration=n_calib,
tolerance_quantile=tol_quant, use_seed=TRUE)
ABC_Wegmann<
hist(ABC_Wegmann $param[,1])
hist(ABC_Wegmann$param[,1])
ABC_Wegmann
ABC_Wegmann$param[,1]
n=1e3
n_calib=1e2
tol_quant=0.2
ABC_Wegmann <-ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n, n_calibration=n_calib,
tolerance_quantile=tol_quant, use_seed=TRUE)
hist(ABC_Wegmann$param[,1])
ABC_Wegmann
toy_model(c(x1,x2,x3,x4))
n=1e4
n_calib=1e3
tol_quant=0.2
ABC_Wegmann <-ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n, n_calibration=n_calib,
tolerance_quantile=tol_quant, use_seed=TRUE)
hist(ABC_Wegmann$param[,1])
ABC_Wegmann
sum_stat_obs
toy_model
n=1e4
tol_quant=0.2
ABC_Wegmann <- ABC_mcmc(method="Marjoram", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n,
tolerance_quantile=tol_quant, use_seed=TRUE)
ABC_Wegmann
n=1e4
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, use_seed=TRUE)
n=1e4
tol = 0.25
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
ABC_sim
hist(ABC_sim$param[,1])
n=1e4
tol = 0.2
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
n=1e4
tol = 0.1
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
dim(ABC_sim$param)
n=1e4
tol = 0.01
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
n=1e4
tol = 0.001
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
n=5e4
tol = 0.001
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
library(coda)
# assuming the data are 10 samples of a normal distribution
# with mean 5.3 and sd 2.7
data =  rnorm(10, mean =5.3, sd = 2.7)
# we want to use ABC to infer the parameters that were used.
# we sample from the same model and use mean and variance
# as summary statstitics. We return true for ABC acceptance when
# the difference to the data is smaller than a certain threshold
meandata <- mean(data)
standarddeviationdata <- sd(data)
ABC_acceptance <- function(par){
# prior to avoid negative standard deviation
if (par[2] <= 0) return(F)
# stochastic model generates a sample for given par
samples <- rnorm(10, mean = par[1], sd = par[2])
# comparison with the observed summary statistics
diffmean <- abs(mean(samples) - meandata)
diffsd <- abs(sd(samples) - standarddeviationdata)
if((diffmean < 0.1) & (diffsd < 0.2)) return(T) else return(F)
}
# we plug this in in a standard metropolis hastings MCMC,
# with the metropolis acceptance exchanged for the ABC acceptance
run_MCMC_ABC <- function(startvalue, iterations){
chain = array(dim = c(iterations+1,2))
chain[1,] = startvalue
for (i in 1:iterations){
# proposalfunction
proposal = rnorm(2,mean = chain[i,], sd= c(0.7,0.7))
if(ABC_acceptance(proposal)){
chain[i+1,] = proposal
}else{
chain[i+1,] = chain[i,]
}
}
return(mcmc(chain))
}
posterior <- run_MCMC_ABC(c(4,2.3),300000)
plot(posterior)
log(100)
toy_prior <- list(c("lognormal",log(100),log(100)),c("lognormal",log(100),log(100)),
c("lognormal",log(100),log(100)),log(100),log(100))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=5e4
tol = 0.001
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
toy_prior <- list(c("lognormal",log(100),log(100)),c("lognormal",log(100),log(100)),
c("lognormal",log(100),log(100)),c("lognormal",log(100),log(100)))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=5e4
tol = 0.001
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
n=5e4
tol = 0.01
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
ABC_sim$param
pdat <- as.data.frame(ABC_sim$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_density_2d()
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_point()
n=1e5
tol = 0.1
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
range(rlnorm(log(100),log(100)))
range(rlnorm(log(100),log(100)))
range(rlnorm(1e5,log(100),log(100)))
range(rlnorm(1e5,log(100),log(10)))
range(rlnorm(1e5,log(10),log(10)))
range(rlnorm(1e5,log(10),log(1)))
range(rlnorm(1e5,log(10),log(10)))
range(rlnorm(1e5,log(10),log(5)))
range(rlnorm(1e5,log(10),log(2)))
range(rlnorm(1e5,log(10),log(3)))
range(rlnorm(1e5,log(10),log(2.5)))
range(rlnorm(1e5,log(1),log(2.5)))
toy_prior <- list(c("lognormal",log(2.5),log(2.5)),c("lognormal",log(2.5),log(2.5)),
c("lognormal",log(2.5),log(2.5)),c("lognormal",log(2.5),log(2.5)))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=1e5
tol = 0.1
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
pdat <- as.data.frame(ABC_sim$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_point()
ggplot(data = pdat,aes(x = V1,y = V3)) +
geom_point()
hist(ABC_sim$param[,1])
mean(ABC_sim$param[,1])
median(ABC_sim$param[,1])
median(ABC_sim$param[10:,1])
median(ABC_sim$param[1:10,1])
ABC_sim
toy_model <- cmpfun(toy_model)
require(compiler)
toy_model <- cmpfun(toy_model)
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
# Summary, just the data - no compression
sum_stat_obs <- obs_data
toy_prior <- list(c("lognormal",log(2.5),log(2.5)),c("lognormal",log(2.5),log(2.5)),
c("lognormal",log(2.5),log(2.5)),c("lognormal",log(2.5),log(2.5)))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=1e5
tol = 0.1
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
hist(ABC_sim$param[,2])
hist(ABC_sim$param[,3])
hist(ABC_sim$param[,4])
#S1 <- mean(c(val1,val2,val3,val4))
#S2 <- sd(c(val1,val2,val3,val4))
return(c(log(val1),log(val2),log(val3),log(val4),log(val5)))
toy_model(c(x1,x2,x3,x4))
toy_model <- function(par){
val1 <- 1e-1*par[1]^4 +
2e-1*par[2]^3.0 +
7e-1*par[3]^2 +
4e-1*par[4];
val2 <- 3e-2*par[1]^4.0 +
5e-2*par[2]^3.0 +
9e-2*par[3]^2.0 +
1e-2*par[4];
val3 <- 7e-3*par[1]^4.0 +
1e-3*par[2]^3.0 +
4e-3*par[3]^2 +
2e-3*par[4];
val4 <- 2e-4*par[1]^4 +
5e-4*par[2]^3 +
8e-4*par[3]^2 +
8e-4*par[4]
val5 <- 9e-5*par[1]^4 +
6e-5*par[2]^3 +
3e-5*par[3]^2 +
1e-5*par[4]
#S1 <- mean(c(val1,val2,val3,val4))
#S2 <- sd(c(val1,val2,val3,val4))
return(c(val1,val2,val3,val4,val5))
}
toy_model <- cmpfun(toy_model)
# Observed data
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
obs_data
logit(34)
require(gtools)
logit(34)
inv.logit(34)
inv.logit(34)
inv.logit(90)
log(1003)
log(1004)
log(1004,10)
log(1003,10)
log(1003,100)
log(1004,100)
log(1004,1)
log(1003,1)
log(1003,2)
log(1004,2)
log(1004,1e4)
log(1003,1e4)
log(1003,0.2)
log(1004,0.2)
log(1004,1e-2)
log(1007,1e-2)
log(1010,1e-2)
log(32,1e-2)
log(12,1e-2)
log(500,1e-2)
log(500,10)
library(sparklyr)
options(sparklyr.java9 = TRUE)
sc <- spark_connect(master = "local")
iris_tbl <- sdf_copy_to(sc, iris, name = "iris_tbl")
media_petal <- iris_div %>%
group_by(Species) %>%
summarise(media = mean(Petal_Length))
sdf_num_partitions(iris_tbl)
iris_div <- sdf_repartition(iris_tbl, partitions = 3)
sdf_num_partitions(iris_div)
library(sparklyr)
spark_available_versions()
setwd("~/Documents/GitHub/Bayesian_Nuclear/BBN_Reactions/He3dp/Real_data/jags")
# 3Hedp analysis
#
# purpose: Real  DATA
#
# - 5 parameters are assumed: Er, gamma_d^2, gamma_n^2 [e1, gin, gout]
#
# - uses the function sfactorHe3dp(obsx1[i], e1, gin, gout), which
#   is a C++ version of a Fortran code that includes Coulomb wave
#   function calculations; JAGS has been recompiled with this C++ function
#
######################################################################
# preparation: remove all variables from the work space
#rm(list=ls())
######################################################################
# data input
# format: obsx, obsy, errobsy; the latter are the individual statistical
# errors of each datum [i]
#
# energy is in units of MeV, and the S-factor in MeVb;
######################################################################
# import packages
library(rjags);library(R2jags);library(mcmcplots)
require(RcppGSL);require(ggplot2);require(ggthemes)
require(nuclear);library(magrittr);library(wesanderson)
library(dplyr);require(ggsci);require(ggmcmc);require(plyr);library(latex2exp)
require(MCMCvis);require(ggridges);require(cowplot)
source("jagsresults.R")
source("theme_rafa.R")
source("plot_Sfactor.R")
source("plot_normfactors.R")
## for block updating [we do not need to center predictor variables]
load.module("glm")
load.module("nuclear")
######################################################################
## Read DATA
ensamble <- read.csv("ensamble.csv",header = T) %>%
mutate(Syst=replace(Syst,Syst==0.06,0.078))  %>% filter(E <= 0.5)
re <- as.numeric(ensamble$dat)
Nre <- length(unique(ensamble$dat))
ik <- as.numeric(ensamble$invK)
Nik <- length(unique(ensamble$invK))
# Radius
# r_i = 6
# r_f = 5
# Literature
#  0.35779   # resonance energy
#  1.0085    # reduced width incoming
#  0.025425   # reduced width outgoing
N <- nrow(ensamble)
obsy <- ensamble$S    # Response variable
obsx <-  ensamble$E   # Predictors
erry <- ensamble$Stat
set <- ensamble$dat
lab <- ensamble$invK
syst = 1 + c(0.03,unique(ensamble$Syst))
#syst <- syst[-3]
M <- 500
xx <- seq(min(obsx),max(obsx),length.out = M)
model.data <- list(obsy = obsy,    # Response variable
obsy2 = obsy,    # Response variable
obsx =  obsx,   # Predictors
erry = erry,
N = nrow(ensamble), # Sample size
syst = syst,
Nre = Nre,
re = re,
Nik = Nik,
ik  = ik,
M = M,
xx = xx
#                  ap  = 5,
#                  ad = 6
)
# Conservative case
######################################################################
Model <- "model{
# LIKELIHOOD informative
for (i in 1:N) {
obsy[i] ~ dnorm(y[i], pow(erry[i], -2))
y[i] ~ dnorm(scale[re[i]]*sfactor3Hedpx(obsx[i], E0,  gd2, gp2, ad, ap, ue[ik[i]]), pow(tau, -2))
}
# Residuals
for (i in 1:N) {
yy[i] ~ dnorm(scale[re[i]]*sfactor3Hedpx(obsx[i], E0,  gd2, gp2, ad, ap, ue[ik[i]]), pow(tau, -2))
res[i] <- obsy[i]-yy[i]
#res[i] <- obsy[i]-sfactor3Hedpx(obsx[i], E0,  gd2, gp2, ad, ap,0)
nres[i] <- res[i]/obsy[i]
}
# LIKELIHOOD broad
for (i in 1:N) {
obsy2[i] ~ dnorm(y_2[i], pow(erry[i], -2))
y_2[i] ~ dnorm(scale[re[i]]*sfactor3Hedpx(obsx[i],  E0_b,  gd2_b, gp2_b, ad_b, ap_b, ue[ik[i]]),pow(tau_2, -2))
}
RSS <- sum(res^2)
# Predicted values
for (j in 1:M){
# Bare...
mux0[j] <- sfactor3Hedpx(xx[j], E0,  gd2, gp2, ad, ap,0)
mux0_2[j] <- sfactor3Hedpx(xx[j], E0_b,  gd2_b, gp2_b, ad_b, ap_b,0)
DeltaM[j] <- mux0[j]/mux0_2[j]
# No inverse Kinematics
mux1[j] <- sfactor3Hedpx(xx[j], E0,  gd2, gp2, ad, ap,ue[1])
yx1[j] ~ dnorm(mux1[j],pow(tau,-2))
# With inverse Kinematics
mux2[j] <- sfactor3Hedpx(xx[j], E0,  gd2, gp2, ad, ap,ue[2])
yx2[j] ~ dnorm(mux1[j],pow(tau,-2))
}
for (k in 1:Nre){
scale[k] ~ dlnorm(log(1.0),pow(log(syst[k]),-2))
}
for (z in 1:Nik){
ue[z] ~ dnorm(0,pow(0.1,-2))T(0,)
}
# PRIORS
# Case I
tau ~  dnorm(0, pow(1,-2))T(0,)
E0  ~  dnorm(0, pow(1,-2))T(0,)
gd2 ~  dnorm(0, pow(1,-2))T(0,)
gp2 ~  dnorm(0, pow(2,-2))T(0,)
ad  <- 6
ap  <- 5
# Case II
tau_2  ~  dnorm(0, pow(1,-2))T(0,)
E0_b  ~   dnorm(0.2,pow(0.02,-2))T(0,)
gd2_b  ~ dnorm(0.3, pow(0.05,-2))T(0,)
gp2_b ~  dnorm(0.04, pow(0.01,-2))T(0,)
ad_b  ~  dnorm(3.5,pow(0.5,-2))T(0,)
ap_b  ~  dnorm(5.5,pow(1,-2))T(0,)
ue_ev[1] <-1e6*ue[1]
ue_ev[2] <-1e6*ue[2]
S_0   <- sfactor3Hedpx(1e-4, E0,  gd2, gp2, ad, ap,0)
S_0b  <- sfactor3Hedpx(1e-4, E0_b,  gd2_b, gp2_b, ad_b, ap_b,0)
}"
inits <- function(){ list(E0 = runif(1,0.3,0.35),E0_b = 0.2,gd2 = 1,
gp2 = runif(1,0.01,0.06),gd2_b = 1) }
set.seed(24)
# JAGS model with R2Jags;
Normfit <- jags(data = model.data,
inits = inits,
parameters.to.save  = c("E0","gd2", "gp2","ue_ev","tau", "ad","ap",
"RSS","mux0","mux1","mux2","scale","DeltaM","S_0",
"S_0b","E0_b","gd2_b",
"gp2_b","tau_2","ad_b","ap_b","res","nres"),
model.file  = textConnection(Model),
n.thin = 10,
n.chains = 3,
n.burnin = 500,
n.iter = 1500)
jagsresults(x = Normfit, params = c("E0","gd2", "gp2","ue","tau", "ad","ap","ue_ev","S_0"),probs = c(0.16, 0.5, 0.84))
temp <- Normfit
temp <- update(temp, n.thin = 5, n.iter = 1000)
plot_Sfactor(Normfit)
source("jagsresults.R")
source("theme_rafa.R")
source("plot_Sfactor.R")
setwd("~/Documents/GitHub/Bayesian_Nuclear/BBN_Reactions/He3dp/Real_data/jags")
source("jagsresults.R")
source("theme_rafa.R")
source("plot_Sfactor.R")
source("jagsresults.R")
source("theme_rafa.R")
source("plot_Sfactor.R")
plot_Sfactor(Normfit)
